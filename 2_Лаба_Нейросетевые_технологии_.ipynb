{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1g4kRP-9lLFRwx7O_hionyhGmCFn6ZIOl",
      "authorship_tag": "ABX9TyNRRy+MosjTsIADxkyZoL7H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorozovDesu/neural_network_technologies/blob/main/2_%D0%9B%D0%B0%D0%B1%D0%B0_%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D1%81%D0%B5%D1%82%D0%B5%D0%B2%D1%8B%D0%B5_%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D0%B8_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "import pandas as pd\n",
        "import os\n",
        "import h5py\n",
        "import PIL\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as pylab\n",
        "pylab.rcParams[\"figure.figsize\"] = (14,8)"
      ],
      "metadata": {
        "id": "Bca8tubdkkFG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Создание многослойной сети для работы с датасетом"
      ],
      "metadata": {
        "id": "-CXIh6Ze4d71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(object): # используется для описания нейронной сети\n",
        "    def __init__(self, sizes): # конструктор класса\n",
        "# self – указатель на объект класса\n",
        "# sizes – список размеров слоев нейронной сети\n",
        "        self.num_layers = len(sizes) # задаем количество слоев нейронной сети\n",
        "        self.sizes = sizes # задаем список размеров слоев нейронной сети\n",
        "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]] # задаем случайные начальные смещения\n",
        "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])] # задаем случайные начальные веса связей\n",
        "\n",
        "    def sigmoid(self,z): # определение сигмоидальной функции активации\n",
        "        return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "    def feedforward(self, a):\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = self.sigmoid(np.dot(w, a)+b)\n",
        "        return a\n",
        "\n",
        "    def SGD( # Стохастический градиентный спуск\n",
        "        self # указатель на объект класса\n",
        "        , training_data # обучающая выборка\n",
        "        , epochs # количество эпох обучения\n",
        "        , mini_batch_size # размер подвыборки\n",
        "        , eta # скорость обучения\n",
        "        , test_data # тестирующая выборка\n",
        "        ):\n",
        "        test_data = list(test_data) # создаем список объектов тестирующей выборки\n",
        "        n_test = len(test_data) # вычисляем длину тестирующей выборки\n",
        "        training_data = list(training_data) # создаем список объектов обучающей выборки\n",
        "        n = len(training_data) # вычисляем размер обучающей выборки\n",
        "        for j in range(epochs): # цикл по эпохам\n",
        "            random.shuffle(training_data) # перемешиваем элементы обучающей выборки\n",
        "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)] # создаем подвыборки\n",
        "            for mini_batch in mini_batches: # цикл по подвыборкам\n",
        "              #print(len(mini_batch[0][0]))\n",
        "              self.update_mini_batch(mini_batch, eta) # один шаг градиентного спуска\n",
        "            print (\"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data), n_test)) # смотрим прогресс в обучении\n",
        "\n",
        "    def update_mini_batch( # Шаг градиентного спуска\n",
        "        self # указатель на объект класса\n",
        "        , mini_batch # подвыборка\n",
        "        , eta # скорость обучения\n",
        "        ):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases] # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights] # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y) # послойно вычисляем градиенты dC/db и dC/dw для текущего прецедента (x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)] # суммируем градиенты dC/db для различных прецедентов текущей подвыборки\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)] # суммируем градиенты dC/dw для различных прецедентов текущей подвыборки\n",
        "        self.weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)] # обновляем все веса w нейронной сети\n",
        "        self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)] # обновляем все смещения b нейронной сети\n",
        "\n",
        "    def backprop( # Алгоритм обратного распространения\n",
        "        self # указатель на объект класса\n",
        "      ,x # вектор входных сигналов ,\n",
        "      ,y # ожидаемый вектор выходных сигналов\n",
        "      ):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases] # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights] # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "        # определение переменных\n",
        "        activation = x # выходные сигналы слоя (первоначально соответствует выходным сигналам 1-го слоя или входным сигналам сети)\n",
        "        activations = [x] # список выходных сигналов по всем слоям (первоначально содержит только выходные сигналы 1-го слоя)\n",
        "        zs = [] # список активационных потенциалов по всем слоям (первоначально пуст)\n",
        "        # прямое распространение\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            z = np.dot(w, activation)+b # считаем активационные потенциалы текущего слоя\n",
        "            zs.append(z) # добавляем элемент (активационные потенциалы слоя) в конец списка\n",
        "            activation = self.sigmoid(z) # считаем выходные сигналы текущего слоя, применяя сигмоидальную функцию активации к активационным потенциалам слоя\n",
        "            activations.append(activation) # добавляем элемент (выходные сигналы слоя) в конец списка\n",
        "  # обратное распространение\n",
        "        delta = self.cost_derivative(activations[-1], y) * self.sigmoid_prime(zs[-1]) # считаем меру влияния нейронов выходного слоя L на величину ошибки (BP1)\n",
        "        nabla_b[-1] = delta # градиент dC/db для слоя L (BP3)\n",
        "        nabla_w[-1] = np.dot(delta, activations[-2].transpose()) # градиент dC/dw для слоя L (BP4)\n",
        "        for l in range(2, self.num_layers):\n",
        "          z = zs[-l] # активационные потенциалы l-го слоя (двигаемся по списку справа налево)\n",
        "          sp = self.sigmoid_prime(z) # считаем сигмоидальную функцию от активационных потенциалов l-го слоя\n",
        "          delta = np.dot(self.weights[-l+1].transpose(), delta) * sp # считаем меру влияния нейронов l-го слоя на величину ошибки (BP2)\n",
        "          nabla_b[-l] = delta # градиент dC/db для l-го слоя (BP3)\n",
        "          nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())# градиент dC/dw для l-го слоя (BP4)\n",
        "        return (nabla_b, nabla_w)\n",
        "\n",
        "    def evaluate(self, test_data): # Оценка прогресса в обучении\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y): # Вычисление частных производных стоимостной функции по выходным сигналам последнего слоя\n",
        "      return (output_activations-y)\n",
        "\n",
        "    def sigmoid_prime(self,z):# Производная сигмоидальной функции\n",
        "      return self.sigmoid(z)*(1-self.sigmoid(z))\n"
      ],
      "metadata": {
        "id": "cityK9CivlKj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = 'drive/MyDrive/archive/all_letters_image/'\n",
        "all_letters_filename = os.listdir(input_folder)\n",
        "len(all_letters_filename)"
      ],
      "metadata": {
        "id": "EeDJyj1rv3BP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b8c7c37-5052-4892-ca75-412dcad83771"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1030"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Это одно из наших изображений. Размер каждого изображения составляет 32 на 32 пикселя.\n",
        "#Затем мы преобразуем каждое изображение в 3d-массив numpy.\n",
        "i = Image.open(\"drive/MyDrive/archive/all_letters_image/01_11.png\")\n",
        "i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "J2rcRj7Oa9q6",
        "outputId": "2e71297d-a7db-47ea-9627-1ad01dc44974"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=32x32>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i_arr = np.array(i)\n",
        "# i_arr\n",
        "# Все 32 матрицы внутри этого массива представляют собой одно изображение.\n",
        "# Каждая матрица представляет собой 1 строку этого изображения.\n",
        "# Длина одной строки изображения составляет 32 пикселя, поэтому каждая матрица имеет 32 строки.\n",
        "# Каждая строка матрицы имеет 4 столбца и представляет собой 1 пиксель. Для этого пикселя каждый столбец представляет собой значения цвета - насколько он красный, зеленый и синий - плюс непрозрачность цветов (последний столбец).\n",
        "# Поэтому каждая матрица имеет размер 32 на 4. Общее количество пикселей в одном изображении составляет 32 * 32 = 1024.\n",
        "\n",
        "# Каждое значение цвета находится в диапазоне [0:255].\n",
        "# Это означает, что для каждого цвета существует 256 оттенков. В сумме все комбинации этих цветов дают нам 256ˆ3 = 16 777 216 возможных цветов.\n",
        "\n"
      ],
      "metadata": {
        "id": "vOD7rNubbUWn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Функция для преобразования изображения в тензор\n",
        "# Параметры:\n",
        "# - img_name: Имя файла изображения\n",
        "# - input_folder: Путь к папке, где находится изображение\n",
        "# Возвращает:\n",
        "# - Тензорное представление изображения\n",
        "def img_to_array(img_name, input_folder):\n",
        "    # Загрузка изображения из указанной папки и изменение его размера до 32x32 пикселей\n",
        "    img = image.load_img(input_folder + img_name, target_size=(32, 32))\n",
        "\n",
        "    # Преобразование изображения в массив NumPy\n",
        "    x = image.img_to_array(img)\n",
        "\n",
        "    # Расширение размерности массива для подготовки его к обработке нейронной сетью\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "# Функция для преобразования списка имен изображений в тензор\n",
        "# Параметры:\n",
        "# - img_names: Список имен файлов изображений\n",
        "# - input_folder: Путь к папке, где находятся изображения\n",
        "# Возвращает:\n",
        "# - Массив NumPy, содержащий тензоры всех изображений из списка\n",
        "def data_to_tensor(img_names, input_folder):\n",
        "    # Создание списка тензоров путем применения функции img_to_array к каждому имени изображения\n",
        "    list_of_tensors = [img_to_array(img_name, input_folder) for img_name in img_names]\n",
        "\n",
        "    # Стекирование отдельных тензоров вертикально для создания одного массива NumPy\n",
        "    return np.vstack(list_of_tensors)\n"
      ],
      "metadata": {
        "id": "0BKFVqtxbyNI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных из CSV-файла в переменную \"data\"\n",
        "data = pd.read_csv(\"drive/MyDrive/archive/all_letters_info.csv\")\n",
        "# Извлечение имен файлов изображений из столбца \"file\"\n",
        "image_names = data['file']\n",
        "# Извлечение букв из столбца \"letter\"\n",
        "letters = data['letter']\n",
        "# Извлечение информации о фоне из столбца \"background\" и преобразование в массив\n",
        "backgrounds = data['background'].values\n",
        "# Извлечение меток (label) из столбца \"label\" и преобразование в массив\n",
        "targets = data['label'].values\n",
        "# Преобразование имен изображений в тензоры с использованием ранее определенной функции \"data_to_tensor\"\n",
        "tensors = data_to_tensor(image_names, input_folder)\n",
        "# Вывод первого тензора (тензора, соответствующего первому изображению) из полученного массива\n",
        "print(tensors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "00BocQQzceSU",
        "outputId": "8a90e543-51e6-42e8-c3b2-d29892422e68"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f77a51cb12b0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbackgrounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'background'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-dc95e0c237a6>\u001b[0m in \u001b[0;36mdata_to_tensor\u001b[0;34m(img_names, input_folder)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Создание списка тензоров путем применения функции img_to_array к каждому имени изображения\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlist_of_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Стекирование отдельных тензоров вертикально для создания одного массива NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-dc95e0c237a6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Создание списка тензоров путем применения функции img_to_array к каждому имени изображения\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlist_of_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Стекирование отдельных тензоров вертикально для создания одного массива NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-dc95e0c237a6>\u001b[0m in \u001b[0;36mimg_to_array\u001b[0;34m(img_name, input_folder)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Загрузка изображения из указанной папки и изменение его размера до 32x32 пикселей\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Преобразование изображения в массив NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/archive/all_letters_image/05_24.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывод размера (формы) массива тензоров\n",
        "print('Форма тензоров:', tensors.shape)\n",
        "# Вывод размера (формы) массива меток (целевых значений)\n",
        "print('Форма меток (целевых значений):', targets.shape)"
      ],
      "metadata": {
        "id": "i3skQmT0czqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для отображения изображений из файлов с использованием OpenCV\n",
        "# Параметры:\n",
        "# - img_path: Путь к файлу изображения\n",
        "# - ax: Объект для отображения изображения (область на графике)\n",
        "def display_images(img_path, ax):\n",
        "    # Загрузка изображения из указанного пути\n",
        "    img = cv2.imread(input_folder + img_path)\n",
        "\n",
        "    # Отображение изображения, преобразовав его из формата BGR в RGB\n",
        "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# Создание графического окна с определенными размерами\n",
        "fig = plt.figure(figsize=(16, 4))\n",
        "\n",
        "# Цикл для отображения 12 изображений\n",
        "for i in range(12):\n",
        "    # Создание области для каждого изображения внутри графического окна\n",
        "    ax = fig.add_subplot(2, 6, i + 1, xticks=[], yticks=[], title=letters[i * 100])\n",
        "\n",
        "    # Вызов функции для отображения изображения с указанным именем файла и заданной областью (ax)\n",
        "    display_images(image_names[i * 100], ax)"
      ],
      "metadata": {
        "id": "XRXTtoOKdECI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Рассмотрим распределение меток\n",
        "g = sns.countplot(targets)"
      ],
      "metadata": {
        "id": "eccsqbKSdne-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Классы идеально сбалансированы, что очень важно для классификационной модели.\n",
        "# Если классы несбалансированы, то модель будет пытаться максимизировать точность\n",
        "# для большинства классов, оставляя без внимания другие классы, что приведет к менее точным прогнозам для меньшинств."
      ],
      "metadata": {
        "id": "htCaopw9dtoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}